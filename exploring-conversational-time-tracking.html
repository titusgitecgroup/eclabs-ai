<!doctype html>
<html lang="en">

<head lang="en">
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Exploring Conversational Time Tracking through Whisper, spaCy and Mirascope</title>
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet"
    integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css">
  <link rel="stylesheet" href="style.css">

</head>

<body>
  <nav class="navbar navbar-expand-lg bg-dark mb-3" data-bs-theme="dark">
    <div class="container-sm">
      <a class="navbar-brand " href="index.html">ecLabs</a>
      <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent"
        aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav mb-2 mb-lg-0">

          <li class="nav-item">
            <a class="nav-link active" href="exploring-conversational-time-tracking.html">Tech</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="#">Business</a>
          </li>
        </ul>

      </div>
    </div>
  </nav>

  <div class="container-blog">
    <div class="home-banner mb-3">
      <div class=""><img src="images/banner-1.jpg" alt="" class="img-fluid me-4 rounded"></div>
    </div>

    <div class="table-contents p-4 border rounded mb-3">
      <h5 class="mb-3">Table of contents</h5>
      <ul class="list-unstyled fs-7 mb-0">
        <li class=""><a href="#intro">Introduction</a></li>
        <li class="">
          <a href="#pre_req">Prerequisites</a>

          <ul class="list-styles list-unstyled ms-3">
            <li>
              <a href="#whisper_loc">
                <i class="bi bi-chevron-right"></i>
                Whisper
              </a>
            </li>
            <li><a href="#spacy_loc">
                <i class="bi bi-chevron-right"></i>
                spaCy
              </a>
            </li>
            <li><a href="#mirascope_loc">
                <i class="bi bi-chevron-right"></i>
                Mirascope.io
              </a>
            </li>
          </ul>
        </li>
        <li class="mb-0">
          <a href="#functions">Functions</a>

          <ul class="list-styles list-unstyled ms-3">
            <li>
              <a href="#ex_f_a">
                <i class="bi bi-chevron-right"></i>
                extract_text_from_audio
              </a>
            </li>
            <li><a href="#sp_t_sp">
                <i class="bi bi-chevron-right"></i>
                split_tasks_using_spacy
              </a></li>
            <li><a href="#ex_f_t">
                <i class="bi bi-chevron-right"></i>
                extract_task_entities_from_text
              </a></li>
          </ul>
        </li>
      </ul>
    </div>
    <div>

      <div id="intro" class="pt-3">
        <h2 class="mb-3">Introduction</h2>
        <p>
          In today's fast-paced business environment, extracting specific task entity information from audio files or
          text documents is crucial for enhancing productivity and decision-making. By integrating Whisper, spaCy, and
          [Mirascope.io](http://mirascope.io/), organizations can create a robust
          system for accurately identifying and processing relevant data from various sources. Whisper offers advanced
          speech recognition capabilities, converting spoken words into text with high precision. spaCy, a powerful
          natural language processing library, further analyzes and extracts key
          entities from the text. [Mirascope.io](http://mirascope.io/) provides a user-friendly interface for managing
          and visualizing the extracted information.
        </p>
        <p>
          This integration is invaluable for businesses across industries, enabling automated meeting transcriptions,
          streamlined customer support, and efficient data entry processes. By leveraging these technologies, companies
          can improve data accuracy, reduce manual workload, and gain actionable
          insights, ultimately driving better business outcomes. In this article, we delve into the technical aspects
          and real-world applications of this integrated approach.
        </p>
      </div>

      <div id="pre_req" class="pt-3 pb-2 mb-4">
        <h2 class="mb-4">Prerequisites</h2>

        <div class="mb-2">Before getting into it, the following prerequisites needed to be installed or created</div>
        <ul class="">
          <li class="">Python 3.9x version</li>
          <li class="">A valid OpenAI API key</li>
          <li class="">Mirascope</li>
          <li class="">spaCy</li>
        </ul>
      </div>

      <div class="mb-4 pb-4">
        <p class="p-2 bg-light fw-medium">Lets first understand the core packages and their characteristics before we
          delve into the code behind it.</p>
        <div id="whisper_loc" class="whisper pt-2">
          <h4>Whisper</h4>
          <p>
            Whisper, developed by OpenAI, is an advanced automatic speech recognition (ASR) system designed to
            transcribe spoken language into written text. The process begins with the input of an audio file, which
            Whisper processes to convert the spoken words into a text format. This transcribed
            text
            can then be used for further analysis, making it easier to identify and extract specific entities. Whisper's
            primary function is to facilitate the transformation of audio data into a textual form, enabling businesses
            to analyze and utilize spoken information more effectively in various
            applications, such as meeting transcriptions, customer service, and content analysis.
          </p>
        </div>
        <div id="spacy_loc" class="spacy pt-4">
          <h4>spaCy</h4>
          <p>
            SpaCy is a powerful and versatile natural language processing (NLP) library in Python, providing tools for
            various NLP tasks, including Named Entity Recognition (NER). NER can identify entities such as names, dates,
            organizations, and more within a text. Once audio is transcribed by
            Whisper, the resulting text can be fed into spaCy. By utilizing spaCy’s NER capabilities, specific entities
            can be extracted from the transcribed text.
          </p>
        </div>
        <div id="mirascope_loc" class="mirascope pt-4">
          <h4>Mirascope.io</h4>
          <p class="m-0">
            Mirascope.io is a platform designed to visualize and analyze data, particularly for more advanced analytics
            and insights. After entities are extracted using spaCy, Mirascope.io can be used to extract task entities
            from these entities. Additionally, Mirascope.io aids in performing more
            advanced analytics on the extracted data, offering deeper insights.
          </p>
        </div>
      </div>

      <p class="p-2 bg-light fw-medium">
        Lets look at three main functions that performs our desired actions.
      </p>

      <div class="main-functions pb-4">
        <ul class="m-0 p-0 list-unstyled">
          <li id="ex_f_a">
            <h4>extract_text_from_audio</h4>
            <p class="mt-4">
              This function takes a file path as a string input and returns a string (the transcribed text)
            </p>

            <div class="code-block p-4 border bg-dark rounded mb-4">
              <code>
                <div class="text-highlight">def</div> extract_text_from_audio(file_path) -> <span class="keyword">str</span>: <br>
                  <div class="text-indent">
                    <span class="text-highlight ">try:</span><br>
                    <div class="comment ">Initialize the OpenAI client</div>
                    client = OpenAI(api_key=OPENAI_API_KEY, project=OPENAI_PROJECT_ID)<br><br>
                    <div class="comment">Open the audio file in binary read mode</div>
                    with <span class="keyword">open</span>(file_path, "<span class="keyword">rb</span>") as audio_file:
                  </div>
                  <br>
		
                <div class="comment"># Create a transcription request</div>
                transcription = client.audio.transcriptions.create(
                <div class="text-indent">
                  model="<span class="keyword">whisper-1</span>",
                  <span class="keyword">file</span>=audio_file)
                </div>
                <br>
		
              <div class="text-indent">
                <div class="comment"># Return the transcribed text</div>
                <span class="text-highlight">return</span> transcription.text	<br>
              </div>

              <span class="text-highlight">except</span> Exception as e: <br>
              <span class="text-highlight text-indent">raise</span> Exception (<span class="keyword">f"Exception in extract_text_from_audio >></span> {str(e)}<span class="keyword">"</span>)
              </code>
            </div>

            <ul>
              <li>
                <div>Initialize OpenAI Client:</div>
                <p>
                  <span class="fw-semibold">**client = openai.OpenAI(api_key=OPENAI_API_KEY,
                    project=OPENAI_PROJECT_ID)**</span> - <br>
                  This line initializes the OpenAI client using the provided API key and project ID.
                </p>
              </li>

              <li>
                <div>File Handling</div>
                <div class="fw-semibold">with open(file_path, "rb") as audio_file: </div>
                <p>
                  This opens the audio file in binary read mode ("rb"). The with statement ensures that the file is
                  properly closed after it is used, even if an error occurs.
                </p>
              </li>

              <li>
                <div>Create Transcription Request</div>
                <div class="fw-semibold">transcription = client.audio.transcriptions.create(model="whisper-1",
                  file=audio_file) - </div>
                <p>
                  This sends the audio file to the OpenAI API for transcription using the whisper-1 model.
                </p>
              </li>
            </ul>
          </li>

          <li id="sp_t_sp" class="pt-4">
            <h4><code class="code-sentence fs-5">split_tasks_using_spacy</code> Function Explanation:</h4>

            <p>
              This <code class="code-sentence">split_tasks_using_spacy</code> function takes a text input and a list of
              action verbs. It uses spaCy, a natural language processing library, to split the text into individual
              tasks based on the presence of these action verbs in the sentences.
            </p>

            <div class="code-block p-3 border bg-dark rounded mb-4">
              <code>
                <span class="text-highlight">from</span> typing <span class="text-highlight">import</span> List
                <span class="text-highlight">import</span> spacy <br> <br>

                <div class="comment"># Load the spaCy model</div>
                nlp = spacy.load("<span class="keyword">en_core_web_sm</span>") <br><br>

                <span class="text-highlight">def</span> split_tasks_using_spacy(txt:<span class="keyword">str</span>, action_verbs:List[<span class="keyword">str</span>]): <br>
                  <span class="text-highlight text-indent">try</span>: <br>
                    <div class="text-indent">
                      tasks:<span class="keyword">list</span>[<span class="keyword">str</span>] = [] <br>
                      doc = nlp(txt)
                    </div> 
                    <br>

                    <div class="text-indent">
                      <div class="comment"># Extract tasks</div>
                      <span class="text-highlight">for</span> sent <span class="text-highlight">in</span> doc.sents: <br>
                        <div class="text-indent">
                          <span class="comment"># Parse the sentence</span>
                          sent_doc = nlp(sent.text.strip()) <br>
                          <span class="text-highlight">for</span> token <span class="text-highlight">in</span> sent_doc:
                         <br>
                          <span class="comment"># Check if the token is an actionable verb and the root of the sentence</span> <br>
                        <span class="text-highlight">if</span> action_verbs: <br>
                          <span class="text-highlight text-indent">if</span> token.lemma_ <span class="text-highlight">in</span> action_verbs: <span class="comment">#and token.dep_ == "ROOT":</span> <br>
                            <span class="text-indent">tasks.append(sent.text.strip())</span> <br>
                            <span class="text-highlight text-indent">break</span> <br>
                        <span class="text-highlight">else</span>: <br>
                        <span class="text-indent">tasks.append(sent.text.strip())</span> <br>
                      </div>
                            <span class="text-highlight">except</span> Exception <span class="text-highlight">as</span> e: <br>
                              <span class="text-highlight text-indent">raise</span> Exception(<span class="keyword">f"Exception in split_tasks_using_spacy >></span> {<span class="keyword">str</span>(e)}<span class="keyword">"</span>) <br>
                            <span class="text-highlight">return</span> tasks
                    </div>
              </code>
            </div>

            <ol>
              <li>
                <div>Load spaCy Model</div>
                <p>
                  <span class="fw-medium">nlp = spacy.load("en_core_web_sm")</span> - Loads the English core small model
                  from spaCy, which contains pre-trained pipelines for various NLP tasks.
                </p>
              </li>

              <li>
                <div>Process the Text</div>
                <p>
                  <span class="fw-medium">doc = nlp(txt)</span> - Uses the spaCy model to process the input text,
                  creating a Doc object that contains linguistic annotations.
                </p>
              </li>

              <li>
                <div>Initialize Tasks List with an empty list</div>

              </li>

              <li>
                <div>Iterates over the sentences in the doc (Doc object - processed text)</div>
                <p>
                  <span class="fw-medium">sent_doc = nlp(sent.text.strip())</span> - processes each sentence
                  individually. <br>

                  Check for Action Verbs <br>

                  <span class="fw-medium">for token in sent_doc:</span> - Iterates over the tokens (words) in the
                  sentence. <br>

                  <span class="fw-medium">if action_verbs:</span> - Checks if the list of action verbs is provided. <br>

                  <span class="fw-medium ps-2">if token.lemma_ in action_verbs:</span> - Checks if the lemma (base form)
                  of the token is in the list of action verbs. <br>

                  <span class="fw-medium ps-4">tasks.append(sent.text.strip())</span> - If an action verb is found, adds
                  the sentence to the tasks list. <br>

                  <span class="fw-medium ps-4">break</span> - Breaks out of the loop once an action verb is found in the
                  sentence. <br>

                  <span class="fw-medium">else:</span> - If no action verbs are provided, adds all sentences to the
                  tasks list. <br>

                  <span class="fw-medium ps-4">tasks.append(sent.text.strip())</span>
                </p>
              </li>
            </ol>
          </li>


          <li id="ex_f_t" class="pt-4">
            <h4>extract_task_entities_from_text</h4>

            <p>
              This function is designed to process a TaskInfo object and extract detailed tasks using OpenAI's language
              models, leveraging both specific action verbs (using spaCy) and general text processing.
            </p>

            <div class="code-block p-3 border bg-dark rounded mb-4">
              <code>
                <span class="text-highlight">def</span> extract_task_entities_from_text(taskInfo:TaskInfo) -> TaskDetails: <br>
                  <span class="text-highlight">try</span>:	<br>
                    tasks_found:<span class="keyword">bool</span> = <span class="text-highlight">False</span><br>
                    taskDetails = TaskDetails() <br>
                    taskDetails.<span class="keyword">input</span> = taskInfo <br>
                    taskDetails.tasks = [] <br>
                    call_params=OpenAICallParams(model=taskInfo.gptModel) <br>
                    TaskExtractor.api_key = OPENAI_API_KEY <br> <br>
                    
                    <span class="text-highlight">if</span> taskInfo.useActionVerbs <span class="text-highlight">and</span> <span class="keyword">hasattr</span>(taskInfo, '<span class="keyword">actionVerbs</span>') <span class="text-highlight">and</span> taskInfo.actionVerbs:
                      tasks = split_tasks_using_spacy(taskInfo.text, taskInfo.actionVerbs) <br>
                      <span class="text-highlight">if</span> tasks: <br>
                        tasks_found = <span class="text-highlight">True</span> <br>
                        <span class="text-highlight">for</span> _task <span class="text-highlight">in</span> tasks: <br>
                          task = TaskExtractor(extract_schema=Task, task=_task, call_params=call_params).extract() <br>
                          taskDetails.tasks.append(task)

                          <br><br>
                          
                    <span class="text-highlight">if not</span> tasks_found: <br>
                      taskDetails = TaskExtractor(extract_schema=TaskDetails, task=taskInfo.text, call_params=call_params).extract()

                      <br><br>
                    
                    <span class="text-highlight">return</span> taskDetails <br>
                  <span class="text-highlight">except</span> Exception <span class="text-highlight">as</span> e: <br>
                    <span class="text-highlight">raise</span> Exception (<span class="keyword">f"Exception in extract_task_entities_from_text >></span> {<span class="keyword">str</span>(e)}<span class="keyword">"</span>)
              </code>

            </div>

            <ol>
              <li>
                <div>
                  Input: <span class="fw-medium">TaskInfo</span> object
                </div>

                <div class="code-block p-3 border bg-dark rounded mb-4">
                  <code>
                    <span class="text-highlight">class</span> TaskInfo(BaseModel): <br>
                        text:<span class="keyword">str</span> = <span class="keyword">''</span>    <br>
                        gptModel:<span class="keyword">str</span> = <span class="keyword">'gpt-4o'</span> <br>
                        useActionVerbs:<span class="keyword">bool</span> = <span class="text-highlight">False</span> <br>
                        actionVerbs:List[<span class="keyword">str</span>] = [] 
                  </code>
                </div>

                <p>
                  <span class="text-danger">TaskInfo</span> - stores all configuration related information such as <span
                    class="fw-medium">text</span> (input), <span class="fw-medium">gptModel</span> (used by <span
                    class="fw-medium">mirascope</span>), <span class="fw-medium">useActionVerbs</span>
                  and <span class="fw-medium">actionVerbs</span> (used by <span class="fw-medium">spaCy</span>). It uses
                  the pydantic.BaseModel as its base class, ensuring data validation and serialization capabilities.
                </p>
              </li>


              <li>
                <div>Create and initialize the properties of TaskDetails object</div>
                <div class="code-block p-3 border bg-dark rounded mb-4">
                  <code>
                    <span class="text-highlight">class</span> TaskDetails(BaseModel): <br>
                    <span class="keyword">input</span>: Optional[<span class="keyword">str</span>] = <span class="keyword">''</span> <br>
                    tasks: Optional[List[Task]] = <span class="text-highlight">None</span>
                  </code>
                </div>

                <p>
                  <span class="text-danger">TaskDetails</span> - encapsulates a list of tasks along with the input text
                  used to generate these tasks. It uses the <span class="text-danger">pydantic.BaseModel</span> as its
                  base class, which provides data validation and serialization capabilities.
                </p>

                <div class="code-block p-3 border bg-dark rounded mb-4">
                  <code>
                    <span class="text-highlight">class</span> Task(BaseModel): <br>
                    task: <span class="keyword">str</span> = <span class="keyword">''</span> <br>
                    duration: Optional[<span class="keyword">str</span>] = <span class="keyword">''</span> <br>
                    startDate: Optional[date] = <span class="text-highlight">None</span> <br>
                    startTime: Optional[<span class="keyword">str</span>] = '' <br>
                    endDate: Optional[date] = <span class="text-highlight">None</span> <br>
                    endTime: Optional[<span class="keyword">str</span>] = ''
                  </code>
                </div>
              </li>

              <li>
                <div>Using <span class="fw-medium">TaskExtractor</span></div>

                <div class="code-block p-3 border bg-dark rounded mb-4">
                  <code>
                    <span class="text-highlight">class</span> TaskExtractor(OpenAIExtractor[T]):
                    prompt_template = <span class="keyword">"""</span> <br>
                    <span class="keyword">
                      Please provide the text conversation you'd like to convert into task entities: <br>
                      {task} <br> <br>
                    </span>

                    <span class="keyword">
                      and set task's end date to {today}, if the task's end date is 'today' or task has 'just' <br>
                      keyword or task has 'start' keyword. <br>
                      """ <br> <br>
                    </span>    
                  
                    task: <span class="keyword">str</span> <br>
                    today: <span class="keyword">str</span> = dateInISOFormat(today())
                  </code>
                </div>

                <p>
                  <span class="text-danger">TaskExtractor</span> class is designed to create a prompt for extracting
                  task entities from a text conversation using a specified prompt template. It inherits from a generic
                  <span class="text-danger">OpenAIExtractor</span> class which is used for
                  extracting structured information using OpenAI chat models like prompt
                  template with placeholders for task details and the current date. The class attributes include the
                  task text and the current date in ISO format.
                </p>

                <div>Class Attributes</div>
                <div class="ps-2">prompt_template</div>
                <div class="ps-4">A multi-line string that serves as a template for the prompt.</div>
                <div class="ps-4">It includes placeholders {task} and {today}.</div>
                <div class="ps-4">
                  The prompt instructs to convert the provided text conversation into task entities and sets the task's
                  end date based on specific keywords.
                </div>
                <div class="text-danger">task</div>
                <div class="ps-4">
                  A string attribute intended to store the text conversation from which tasks will be extracted.
                </div>
                <div class="text-danger">today</div>
                <p>
                  <span class="ps-4">A string attribute that stores the current date in ISO format.</span> <br>

                  <span class="ps-4">It uses the function <span class="text-danger">dateInISOFormat(today())</span>,
                    which converts the current date to an ISO string format.</span> <br>

                  Split Tasks from Text <br>

                  Split tasks from text only if the <span class="fw-medium">TaskInfo</span> object is configured to use
                  action verbs and it contains action verbs.

                  tasks = <span class="fw-medium">split_tasks_using_spacy(taskInfo.text, taskInfo.actionVerbs)</span>
                  Splits the input text into individual tasks using the provided action verbs.

                  Checks if any tasks were found.

                  <span class="fw-medium">Extract Each Task:</span>

                  <span class="fw-medium">
                    for _task in tasks: Iterates over the found tasks.
                    task = TaskExtractor(extract_schema=Task, task=_task, task=_task, call_params=call_params).extract()
                  </span> Uses TaskExtractor to process each task with the specified schema and call parameters.

                  <span class="fw-medium">taskDetails.tasks.append(task)</span> - appends the extracted task to the
                  taskDetails.tasks list.

                  If no tasks were found, <span class="fw-medium">TaskExtractor</span> is used to extract tasks from the
                  input text.

                  <span class="fw-medium">taskDetails = TaskExtractor(extract_schema=TaskDetails, task=taskInfo.text,
                    call_params=call_params).extract()</span> - extracts TaskDetails directly from the input text.


                </p>
              </li>
            </ol>
          </li>


        </ul>
      </div>


      <div class="conclusion">
        <h4>Conclusion</h4>

        <p>
          Incorporating Whisper, spaCy, and Mirascope.io into a unified system offers businesses a powerful tool for
          extracting and analyzing task entity information from audio files and text documents. Whisper’s advanced
          speech recognition capabilities enable precise conversion of spoken language
          into text, while spaCy’s robust NLP features allow for the detailed extraction of key entities. Mirascope.io
          further enhances this process by providing an intuitive platform for performing advanced analytics on the
          extracted data.
        </p>

        <p>
          This integrated approach significantly boosts productivity and decision-making across various industries by
          automating tasks such as meeting transcriptions, customer support, and data entry. By improving data accuracy
          and reducing manual workloads, organizations can gain actionable
          insights that drive better business outcomes. Adopting these technologies not only streamlines operations but
          also positions businesses to leverage cutting-edge tools for enhanced efficiency and strategic advantage.
        </p>
      </div>
    </div>
  </div>

  <footer class="footer">
    <div class="social-media">
      <img src="images/facebook.svg" alt="Facebook">
      <img src="images/linkedin.png" alt="Twitter">
      <img src="images/Instagram.png" alt="Instagram">
      <!-- Add more social media icons as needed -->
    </div>
    <div class="copyright">
      &copy; 2024 EC Group International. All rights reserved.
    </div>
  </footer>

  <span id="go_top" onclick="topFunction()">
    <i class="bi bi-chevron-up"></i>
  </span>

  <script src="scroll-to-top.js" defer></script>
</body>

</html>