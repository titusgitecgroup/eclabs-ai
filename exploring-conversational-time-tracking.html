<!doctype html>
<html lang="en">

<head lang="en">
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Exploring Conversational Time Tracking through Whisper, spaCy and Mirascope</title>
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
  <link rel="stylesheet" href="style.css">

</head>

<body>
  <nav class="navbar navbar-expand-lg bg-body-tertiary mb-3">
    <div class="container">
      <a class="navbar-brand text-primary" href="#">ECLabs</a>
      <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav ms-5 mb-2 mb-lg-0">
          <li class="nav-item">
            <a class="nav-link " aria-current="page" href="index.html">Home</a>
          </li>
          <li class="nav-item active">
            <a class="nav-link" aria-current="page" href="exploring-conversational-time-tracking.html">Blog</a>
          </li>
        </ul>

      </div>
    </div>
  </nav>

  <div class="container-blog">
    <div class="home-banner mb-3">
      <div class=""><img src="images/banner-1.jpg" alt="" class="img-fluid me-4 rounded"></div>
    </div>

    <div class="table-contents p-4 border rounded mb-3">
      <h5 class="mb-3">Table of contents</h5>
      <ul class="list-unstyled fs-7 mb-0">
        <li class=""><a href="#intro">Introduction</a></li>
        <li class=""><a href="#pre_req">Prerequisites</a></li>
        <li class=""><a href="#models">Models</a></li>
        <li class="mb-0"><a href="#functions">Functions</a></li>
      </ul>
    </div>
    <div>

      <div id="intro" class="pt-3">
        <h3>Introduction</h3>
        <p>
          In today's fast-paced business environment, extracting specific task entity information from audio files or text documents is crucial for enhancing productivity and decision-making. By integrating Whisper, spaCy, and [Mirascope.io](http://mirascope.io/), organizations can create a robust
          system for accurately identifying and processing relevant data from various sources. Whisper offers advanced speech recognition capabilities, converting spoken words into text with high precision. spaCy, a powerful natural language processing library, further analyzes and extracts key
          entities from the text. [Mirascope.io](http://mirascope.io/) provides a user-friendly interface for managing and visualizing the extracted information.
        </p>
        <p>
          This integration is invaluable for businesses across industries, enabling automated meeting transcriptions, streamlined customer support, and efficient data entry processes. By leveraging these technologies, companies can improve data accuracy, reduce manual workload, and gain actionable
          insights, ultimately driving better business outcomes. In this article, we delve into the technical aspects and real-world applications of this integrated approach.
        </p>
      </div>

      <div id="pre_req" class="pt-3 pb-2">
        <h3>Prerequisites</h3>

        <div>Before getting into it, the following prerequisites needed to be installed or created</div>
        <ul>
          <li>Python 3.9x version</li>
          <li>A valid OpenAI API key</li>
          <li>Mirascope</li>
          <li>spaCy</li>
        </ul>
      </div>

      <div class="mb-4">
        <p class="p-2 bg-light fw-medium">Lets first understand the core packages and their characteristics before we delve into the code behind it.</p>
        <div class="whisper">
          <h4>Whisper</h4>
          <p>
            Whisper, developed by OpenAI, is an advanced automatic speech recognition (ASR) system designed to transcribe spoken language into written text. The process begins with the input of an audio file, which Whisper processes to convert the spoken words into a text format. This transcribed
            text
            can then be used for further analysis, making it easier to identify and extract specific entities. Whisper's primary function is to facilitate the transformation of audio data into a textual form, enabling businesses to analyze and utilize spoken information more effectively in various
            applications, such as meeting transcriptions, customer service, and content analysis.
          </p>
        </div>
        <div class="spacy">
          <h4>spaCy</h4>
          <p>
            SpaCy is a powerful and versatile natural language processing (NLP) library in Python, providing tools for various NLP tasks, including Named Entity Recognition (NER). NER can identify entities such as names, dates, organizations, and more within a text. Once audio is transcribed by
            Whisper, the resulting text can be fed into spaCy. By utilizing spaCy’s NER capabilities, specific entities can be extracted from the transcribed text.
          </p>
        </div>
        <div class="mirascope">
          <h4>Mirascope.io</h4>
          <p class="m-0">
            Mirascope.io is a platform designed to visualize and analyze data, particularly for more advanced analytics and insights. After entities are extracted using spaCy, Mirascope.io can be used to extract task entities from these entities. Additionally, Mirascope.io aids in performing more
            advanced analytics on the extracted data, offering deeper insights.
          </p>
        </div>
      </div>

      <p class="p-2 bg-light fw-medium">Lets look at three main functions that performs our desired actions.</p>

      <div class="main-functions pb-4">
        <ol class="m-0 p-0">
          <li>
            <h4>extract_text_from_audio</h4>
            <p>
              This function takes a file path as a string input and returns a string (the transcribed text)
            </p>

            <div class="code-block p-3 border bg-dark rounded mb-4">
              <code>
                <div class="start-text">def</div> extract_text_from_audio(file_path) -> <span class="keyword">str</span>: <br>
	              <span class="start-text">try:</span><br>
                <div class="comment"># Initialize the OpenAI client</div>
                client = OpenAI(api_key=OPENAI_API_KEY, project=OPENAI_PROJECT_ID)<br><br>
		
                <div class="comment"># Open the audio file in binary read mode</div>
                with <span class="keyword">open</span>(file_path, "<span class="keyword">rb</span>") as audio_file:<br><br>
		
                <div class="comment"># Create a transcription request</div>
                transcription = client.audio.transcriptions.create(
                model="<span class="keyword">whisper-1</span>",
                <span class="keyword">file</span>=audio_file)<br><br>
		
              <div class="comment"># Return the transcribed text</div>
              <span class="start-text">return</span> transcription.text	<br>
              <span class="start-text">except</span> Exception as e: <br>
              <span class="start-text">raise</span> Exception (<span class="keyword">f"Exception in extract_text_from_audio >></span> {str(e)}<span class="keyword">"</span>)
              </code>
            </div>

            <ol>
              <li>
                <div>Initialize OpenAI Client:</div>
                <p>
                  <span class="fw-semibold">**client = openai.OpenAI(api_key=OPENAI_API_KEY, project=OPENAI_PROJECT_ID)**</span> - <br>
                  This line initializes the OpenAI client using the provided API key and project ID.
                </p>
              </li>

              <li>
                <div>File Handling</div>
                <div class="fw-semibold">with open(file_path, "rb") as audio_file: </div>
                <p>
                  This opens the audio file in binary read mode ("rb"). The with statement ensures that the file is properly closed after it is used, even if an error occurs.
                </p>
              </li>

              <li>
                <div>Create Transcription Request</div>
                <div class="fw-semibold">transcription = client.audio.transcriptions.create(model="whisper-1", file=audio_file) - </div>
                <p>
                  This sends the audio file to the OpenAI API for transcription using the whisper-1 model.
                </p>
              </li>
            </ol>
          </li>

          <li>
            <h4>split_tasks_using_spacy</h4>

            <p>
              This function takes a text input and a list of action verbs. It uses spaCy, a natural language processing library, to split the text into individual tasks based on the presence of these action verbs in the sentences.
            </p>

            <div class="code-block p-3 border bg-dark rounded mb-4">
              <code>
                <span class="start-text">from</span> typing <span class="start-text">import</span> List
                <span class="start-text">import</span> spacy <br> <br>

                <div class="comment"># Load the spaCy model</div>
                nlp = spacy.load("<span class="keyword">en_core_web_sm</span>") <br><br>

                <span class="start-text">def</span> split_tasks_using_spacy(txt:<span class="keyword">str</span>, action_verbs:List[<span class="keyword">str</span>]):
                  <span class="start-text">try</span>:
                    tasks:<span class="keyword">list</span>[<span class="keyword">str</span>] = []
                    doc = nlp(txt) <br><br>

                    <div class="comment"># Extract tasks</div>

                    <span class="start-text">for</span> sent <span class="start-text">in</span> doc.sents:

                      <div class="comment"># Parse the sentence</div>

                      sent_doc = nlp(sent.text.strip()) <br>
                      <span class="start-text">for</span> token <span class="start-text">in</span> sent_doc: <br>
                        <div class="comment"># Check if the token is an actionable verb and the root of the sentence</div>
                      <span class="start-text">if</span> action_verbs: <br>
                        <span class="start-text">if</span> token.lemma_ <span class="start-text">in</span> action_verbs: <span class="comment">#and token.dep_ == "ROOT":</span> <br>
                          tasks.append(sent.text.strip()) <br>
                          <span class="start-text">break</span> <br>
                      <span class="start-text">else</span>: <br>
                      tasks.append(sent.text.strip()) <br>
                <span class="start-text">except</span> Exception <span class="start-text">as</span> e: <br>
                  <span class="start-text">raise</span> Exception(<span class="keyword">f"Exception in split_tasks_using_spacy >></span> {<span class="keyword">str</span>(e)}<span class="keyword">"</span>) <br>
                <span class="start-text">return</span> tasks
              </code>
            </div>

            <ol>
              <li>
                <div>Load spaCy Model</div>
                <p>
                  <span class="fw-medium">nlp = spacy.load("en_core_web_sm")</span> - Loads the English core small model from spaCy, which contains pre-trained pipelines for various NLP tasks.
                </p>
              </li>

              <li>
                <div>Process the Text</div>
                <p>
                  <span class="fw-medium">doc = nlp(txt)</span> - Uses the spaCy model to process the input text, creating a Doc object that contains linguistic annotations.
                </p>
              </li>

              <li>
                <div>Initialize Tasks List with an empty list</div>

              </li>

              <li>
                <div>Iterates over the sentences in the doc (Doc object - processed text)</div>
                <p>
                  <span class="fw-medium">sent_doc = nlp(sent.text.strip())</span> - processes each sentence individually. <br>

                  Check for Action Verbs <br>

                  <span class="fw-medium">for token in sent_doc:</span> - Iterates over the tokens (words) in the sentence. <br>

                  <span class="fw-medium">if action_verbs:</span> - Checks if the list of action verbs is provided. <br>

                  <span class="fw-medium ps-2">if token.lemma_ in action_verbs:</span> - Checks if the lemma (base form) of the token is in the list of action verbs. <br>

                  <span class="fw-medium ps-4">tasks.append(sent.text.strip())</span> - If an action verb is found, adds the sentence to the tasks list. <br>

                  <span class="fw-medium ps-4">break</span> - Breaks out of the loop once an action verb is found in the sentence. <br>

                  <span class="fw-medium">else:</span> - If no action verbs are provided, adds all sentences to the tasks list. <br>

                  <span class="fw-medium ps-4">tasks.append(sent.text.strip())</span>
                </p>
              </li>
            </ol>
          </li>


          <li>
            <h4>extract_task_entities_from_text</h4>

            <p>
              This function is designed to process a TaskInfo object and extract detailed tasks using OpenAI's language models, leveraging both specific action verbs (using spaCy) and general text processing.
            </p>

            <div class="code-block p-3 border bg-dark rounded mb-4">
              <code>
                <span class="start-text">def</span> extract_task_entities_from_text(taskInfo:TaskInfo) -> TaskDetails: <br>
                  <span class="start-text">try</span>:	<br>
                    tasks_found:<span class="keyword">bool</span> = <span class="start-text">False</span><br>
                    taskDetails = TaskDetails() <br>
                    taskDetails.<span class="keyword">input</span> = taskInfo <br>
                    taskDetails.tasks = [] <br>
                    call_params=OpenAICallParams(model=taskInfo.gptModel) <br>
                    TaskExtractor.api_key = OPENAI_API_KEY <br> <br>
                    
                    <span class="start-text">if</span> taskInfo.useActionVerbs <span class="start-text">and</span> <span class="keyword">hasattr</span>(taskInfo, '<span class="keyword">actionVerbs</span>') <span class="start-text">and</span> taskInfo.actionVerbs:
                      tasks = split_tasks_using_spacy(taskInfo.text, taskInfo.actionVerbs) <br>
                      <span class="start-text">if</span> tasks: <br>
                        tasks_found = <span class="start-text">True</span> <br>
                        <span class="start-text">for</span> _task <span class="start-text">in</span> tasks: <br>
                          task = TaskExtractor(extract_schema=Task, task=_task, call_params=call_params).extract() <br>
                          taskDetails.tasks.append(task)

                          <br><br>
                          
                    <span class="start-text">if not</span> tasks_found: <br>
                      taskDetails = TaskExtractor(extract_schema=TaskDetails, task=taskInfo.text, call_params=call_params).extract()

                      <br><br>
                    
                    <span class="start-text">return</span> taskDetails <br>
                  <span class="start-text">except</span> Exception <span class="start-text">as</span> e: <br>
                    <span class="start-text">raise</span> Exception (<span class="keyword">f"Exception in extract_task_entities_from_text >></span> {<span class="keyword">str</span>(e)}<span class="keyword">"</span>)
              </code>

            </div>

            <ol>
              <li>
                <div>
                  Input: <span class="fw-medium">TaskInfo</span> object
                </div>

                <div class="code-block p-3 border bg-dark rounded mb-4">
                  <code>
                    <span class="start-text">class</span> TaskInfo(BaseModel): <br>
                        text:<span class="keyword">str</span> = <span class="keyword">''</span>    <br>
                        gptModel:<span class="keyword">str</span> = <span class="keyword">'gpt-4o'</span> <br>
                        useActionVerbs:<span class="keyword">bool</span> = <span class="start-text">False</span> <br>
                        actionVerbs:List[<span class="keyword">str</span>] = [] 
                  </code>
                </div>

                <p>
                  <span class="text-danger">TaskInfo</span> - stores all configuration related information such as <span class="fw-medium">text</span> (input), <span class="fw-medium">gptModel</span> (used by <span class="fw-medium">mirascope</span>), <span class="fw-medium">useActionVerbs</span>
                  and <span class="fw-medium">actionVerbs</span> (used by <span class="fw-medium">spaCy</span>). It uses the pydantic.BaseModel as its base class, ensuring data validation and serialization capabilities.
                </p>
              </li>


              <li>
                <div>Create and initialize the properties of TaskDetails object</div>
                <div class="code-block p-3 border bg-dark rounded mb-4">
                  <code>
                    <span class="start-text">class</span> TaskDetails(BaseModel): <br>
                    <span class="keyword">input</span>: Optional[<span class="keyword">str</span>] = <span class="keyword">''</span> <br>
                    tasks: Optional[List[Task]] = <span class="start-text">None</span>
                  </code>
                </div>

                <p>
                  <span class="text-danger">TaskDetails</span> - encapsulates a list of tasks along with the input text used to generate these tasks. It uses the <span class="text-danger">pydantic.BaseModel</span> as its base class, which provides data validation and serialization capabilities.
                </p>

                <div class="code-block p-3 border bg-dark rounded mb-4">
                  <code>
                    <span class="start-text">class</span> Task(BaseModel): <br>
                    task: <span class="keyword">str</span> = <span class="keyword">''</span> <br>
                    duration: Optional[<span class="keyword">str</span>] = <span class="keyword">''</span> <br>
                    startDate: Optional[date] = <span class="start-text">None</span> <br>
                    startTime: Optional[<span class="keyword">str</span>] = '' <br>
                    endDate: Optional[date] = <span class="start-text">None</span> <br>
                    endTime: Optional[<span class="keyword">str</span>] = ''
                  </code>
                </div>
              </li>

              <li>
                <div>Using <span class="fw-medium">TaskExtractor</span></div>

                <div class="code-block p-3 border bg-dark rounded mb-4">
                  <code>
                    <span class="start-text">class</span> TaskExtractor(OpenAIExtractor[T]):
                    prompt_template = <span class="keyword">"""</span> <br>
                    <span class="keyword">
                      Please provide the text conversation you'd like to convert into task entities: <br>
                      {task} <br> <br>
                    </span>

                    <span class="keyword">
                      and set task's end date to {today}, if the task's end date is 'today' or task has 'just' <br>
                      keyword or task has 'start' keyword. <br>
                      """ <br> <br>
                    </span>    
                  
                    task: <span class="keyword">str</span> <br>
                    today: <span class="keyword">str</span> = dateInISOFormat(today())
                  </code>
                </div>

                <p>
                  <span class="text-danger">TaskExtractor</span> class is designed to create a prompt for extracting task entities from a text conversation using a specified prompt template. It inherits from a generic <span class="text-danger">OpenAIExtractor</span> class which is used for
                  extracting structured information using OpenAI chat models like prompt
                  template with placeholders for task details and the current date. The class attributes include the task text and the current date in ISO format.
                </p>

                <div>Class Attributes</div>
                <div class="ps-2">prompt_template</div>
                <div class="ps-4">A multi-line string that serves as a template for the prompt.</div>
                <div class="ps-4">It includes placeholders {task} and {today}.</div>
                <div class="ps-4">
                  The prompt instructs to convert the provided text conversation into task entities and sets the task's end date based on specific keywords.
                </div>
                <div class="text-danger">task</div>
                <div class="ps-4">
                  A string attribute intended to store the text conversation from which tasks will be extracted.
                </div>
                <div class="text-danger">today</div>
                <p>
                  <span class="ps-4">A string attribute that stores the current date in ISO format.</span> <br>

                  <span class="ps-4">It uses the function <span class="text-danger">dateInISOFormat(today())</span>, which converts the current date to an ISO string format.</span> <br>

                  Split Tasks from Text <br>

                  Split tasks from text only if the <span class="fw-medium">TaskInfo</span> object is configured to use action verbs and it contains action verbs.

                  tasks = <span class="fw-medium">split_tasks_using_spacy(taskInfo.text, taskInfo.actionVerbs)</span> Splits the input text into individual tasks using the provided action verbs.

                  Checks if any tasks were found.

                  <span class="fw-medium">Extract Each Task:</span>

                  <span class="fw-medium">
                    for _task in tasks: Iterates over the found tasks.
                    task = TaskExtractor(extract_schema=Task, task=_task, task=_task, call_params=call_params).extract()
                  </span> Uses TaskExtractor to process each task with the specified schema and call parameters.

                  <span class="fw-medium">taskDetails.tasks.append(task)</span> - appends the extracted task to the taskDetails.tasks list.

                  If no tasks were found, <span class="fw-medium">TaskExtractor</span> is used to extract tasks from the input text.

                  <span class="fw-medium">taskDetails = TaskExtractor(extract_schema=TaskDetails, task=taskInfo.text, call_params=call_params).extract()</span> - extracts TaskDetails directly from the input text.


                </p>
              </li>
            </ol>
          </li>


        </ol>
      </div>


      <div class="conclusion">
        <h4>Conclusion</h4>

        <p>
          Incorporating Whisper, spaCy, and Mirascope.io into a unified system offers businesses a powerful tool for extracting and analyzing task entity information from audio files and text documents. Whisper’s advanced speech recognition capabilities enable precise conversion of spoken language
          into text, while spaCy’s robust NLP features allow for the detailed extraction of key entities. Mirascope.io further enhances this process by providing an intuitive platform for performing advanced analytics on the extracted data.
        </p>

        <p>
          This integrated approach significantly boosts productivity and decision-making across various industries by automating tasks such as meeting transcriptions, customer support, and data entry. By improving data accuracy and reducing manual workloads, organizations can gain actionable
          insights that drive better business outcomes. Adopting these technologies not only streamlines operations but also positions businesses to leverage cutting-edge tools for enhanced efficiency and strategic advantage.
        </p>
      </div>
    </div>
  </div>
</body>

</html>